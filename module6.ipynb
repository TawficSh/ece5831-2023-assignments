{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with loading images:  C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\mnist\\train-images-idx3-ubyte.gz\n",
      "Done with loading labels:  C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\mnist\\train-labels-idx1-ubyte.gz\n",
      "Done with loading images:  C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\mnist\\t10k-images-idx3-ubyte.gz\n",
      "Done with loading labels:  C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch 1, Training Accuracy: 0.11236666666666667\n",
      "Epoch 2, Training Accuracy: 0.11236666666666667\n",
      "Epoch 3, Training Accuracy: 0.11236666666666667\n",
      "Epoch 4, Training Accuracy: 0.11236666666666667\n",
      "Epoch 5, Training Accuracy: 0.11236666666666667\n"
     ]
    }
   ],
   "source": [
    "from mnist_data import MnistData\n",
    "import numpy as np\n",
    "import common as c\n",
    "import pickle\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_data = MnistData()\n",
    "(x_train, t_train), (x_test, t_test) = mnist_data.load()\n",
    "\n",
    "# Initialize the neural network\n",
    "input_size = 28 * 28  # Assuming 28x28 images\n",
    "hidden_size = 100  # Adjust as needed\n",
    "output_size = 10  # Assuming 10 classes for digits 0 to 9\n",
    "net = TwoLayerNet(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define hyperparameters\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training the neural network using SGD with 10 epochs\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for i in range(iters_num):\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "\n",
    "        # Compute the gradients using backpropagation\n",
    "        grads = net.gradient(x_batch, t_batch)\n",
    "\n",
    "        # Update the parameters using SGD\n",
    "        for key in ('w1', 'b1', 'w2', 'b2'):\n",
    "            net.params[key] -= learning_rate * grads[key]\n",
    "\n",
    "    # Print the training accuracy for each epoch\n",
    "    train_acc = net.accuracy(x_train, t_train)\n",
    "    print(f\"Epoch {epoch+1}, Training Accuracy: {train_acc}\")\n",
    "\n",
    "# Save the trained model\n",
    "with open('Tawfic_Shamieh_mnist_nn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_data import MnistData \n",
    "import numpy as np\n",
    "import two_layer_net as tln\n",
    "import train as train\n",
    "from two_layer_net import net\n",
    "\n",
    "img1=r\"C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\Images(num)\\0_1.jpg\"\n",
    "img2=r\"C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\Images(num)\\1_2.jpg\"\n",
    "img3=r\"C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\Images(num)\\2_3.jpg\"\n",
    "img4=r\"C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\Images(num)\\3_4.jpg\"\n",
    "img5=r\"C:\\Users\\ACER\\OneDrive\\Desktop\\ece5831-2023-assignments\\ece5831-2023-assignments\\assignment-5\\Images(num)\\4_5.jpg\"\n",
    "\n",
    "from PIL import Image\n",
    "# Load and preprocess the custom test images\n",
    "# Implement the code to load and preprocess your custom test images\n",
    "\n",
    "custom_test_image_paths = [img1,img2,img3,img4,img5]\n",
    "custom_test_images = []\n",
    "for image_path in custom_test_image_paths:\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = image.resize((28, 28))  # Resize the image to 28x28\n",
    "    image = np.array(image)  # Convert to a NumPy array\n",
    "    image = image.reshape(1, 28 * 28)  # Flatten the image to a 1D array\n",
    "    image = image.astype('float32') / 255  # Normalize pixel values\n",
    "    custom_test_images.append(image)\n",
    "\n",
    "# Use the trained model to make predictions on the custom images\n",
    "# Implement the code to use the trained model for predictions\n",
    "custom_predictions = []\n",
    "for image in custom_test_images:\n",
    "    prediction = net.predict(image)\n",
    "    custom_predictions.append(prediction)\n",
    "\n",
    "# Display or store the predictions for further analysis\n",
    "# Implement the code to display or store the predictions\n",
    "for i, pred in enumerate(custom_predictions):\n",
    "    print(f\"Prediction for {custom_test_image_paths[i]}: {pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
